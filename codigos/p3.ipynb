{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 3: Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1\n",
    "Se implementará la clase `RegresionBayesianaEmpirica`, que heredará las clases [`BaseEstimator`](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html) y [`RegressorMixin`](http://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html), que son clases del paquete [`sklearn.base`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de la clase `RegresionBayesianaEmpirica`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegresionBayesianaEmpirica(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    `RegresionBayesianaEmpirica` es una clase que hereda de `sklearn.base.BaseEstimator` y \n",
    "    `sklearn.base.RegressorMixin` el cual implementa la heurística enunciada en el \n",
    "    informe de la tarea para aproximar los hiperparámetros óptimos de alpha y beta.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha_0, beta_0, tol=1e-5, maxiter=200):\n",
    "        self.alpha = alpha_0\n",
    "        self.beta = beta_0\n",
    "        self.__tol = tol\n",
    "        self.__maxiter = maxiter\n",
    "        \n",
    "    def get_posterior(self, X, y, alpha, beta):\n",
    "        \"\"\"\n",
    "        Recibe una matriz de observaciones 'X' (de dimensiones N x d), el vector de \n",
    "        etiquetas 'y' (de dimensión N) y los hiperparámetros 'alpha' y 'beta'.\n",
    "        \n",
    "        Retorna una tupla (m_N, S_N), dónde 'm_N' corresponde al vector de medias y \n",
    "        'S_N' corresponde a la matriz de covarianzas de la posterior de 'w'.\n",
    "        \"\"\"\n",
    "        # Se ocupa P3-1\n",
    "        # dimensiones\n",
    "        N, d = X.shape\n",
    "        \n",
    "        # Matriz de covarianzas [d x d]\n",
    "        S_N_inv = alpha*np.eye(d) + beta*X.T@X\n",
    "        S_N = np.linalg.inv(S_N_inv) \n",
    "        \n",
    "        # Vector de medias [d]\n",
    "        m_N = beta * (S_N@X.T@y)\n",
    "        \n",
    "        return (m_N, S_N)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Recibe una matriz de observaciones 'X' (de dimensiones N x d) \n",
    "        y un vector de etiquetas 'y' (de dimensión N).\n",
    "        \n",
    "        Ajusta los valores de 'alpha' y 'beta'.\n",
    "        \"\"\"\n",
    "        # Seteamos atributos de los datos y dimensiones\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.N, self.d = self.X.shape\n",
    "        \n",
    "        maxiter_alcanzado = True # Variable para saber si la \n",
    "                                 # máxima iteración ha sido cumplida o no\n",
    "        \n",
    "        for _ in range(self.__maxiter):\n",
    "            # Seteamos alpha_0 y beta_0 \n",
    "            alpha_0, beta_0 = self.alpha, self.beta\n",
    "            \n",
    "            # Calculamos los valores propios de beta * X^t * X\n",
    "            lamb, _ = np.linalg.eig(beta_0 * self.X.T@self.X)\n",
    "            \n",
    "            # Calculamos gamma\n",
    "            gamma = sum([lamb[i] / (alpha_0 + lamb[i]) for i in range(self.d)])\n",
    "            \n",
    "            # Calculamos m_N\n",
    "            m_N, S_N = self.get_posterior(self.X, self.y, alpha_0, beta_0)\n",
    "            \n",
    "            # Calculamos el siguiente valor de alpha\n",
    "            alpha_1 = gamma / np.inner(m_N, m_N)\n",
    "            \n",
    "            # Y calculamos el siguiente valor de beta\n",
    "            beta_1_inv = (1 / (self.N-gamma)) \\\n",
    "                     * sum([(self.y[i] - np.inner(m_N, self.X[i]))**2 for i in range(self.N)])\n",
    "            beta_1 = 1 / beta_1_inv\n",
    "            \n",
    "            # Seteamos estos nuevos valores para alpha y beta\n",
    "            self.alpha, self.beta = alpha_1, beta_1\n",
    "            \n",
    "            # Comparamos para saber si ya se cumplió la condición de cercanía\n",
    "            if (abs(alpha_0 - alpha_1) <= self.__tol\n",
    "               and abs(beta_0 - beta_1) <= self.__tol):\n",
    "                print('tolerancia alcanzada')\n",
    "                maxiter_alcanzado = False\n",
    "                break\n",
    "        \n",
    "        if maxiter_alcanzado:\n",
    "            print('alcanzado numero max de iter')\n",
    "        \n",
    "        return self\n",
    "            \n",
    "    def predict(self, X_, return_std=False)->tuple:\n",
    "        \"\"\"\n",
    "        Recibe una matriz de observaciones 'X_' (de dimensiones N' x d).\n",
    "        \n",
    "        Retorna una tupla (y_, y_std), en dónde 'y_' corresponde al vector de medias y 'y_std' \n",
    "        corresponde al vector de desviaciones estándar asociadas a las observaciones de 'X_'.\n",
    "        Haciendo notar que esto ocurre solo sí 'return_std' es True. En caso contrario, solo retorna \n",
    "        la tupla (y_,).\n",
    "        \n",
    "        Se ocupa la distribución predictiva posterior para estas predicciones.\n",
    "        \"\"\"\n",
    "        # Se ocupa P3-2\n",
    "        # Dimensiones necesarias\n",
    "        N_, d = X_.shape\n",
    "        m_N, S_N = self.get_posterior(self.X, self.y, self.alpha, self.beta)\n",
    "        \n",
    "        y_ = []\n",
    "        y_std = []\n",
    "        for i_ in range(N_):\n",
    "            x_i = X_[i_]\n",
    "            y_i = np.inner(m_N, x_i)\n",
    "            y_std_i = 1/self.beta + x_i.T@S_N@x_i\n",
    "            \n",
    "            y_.append(y_i)\n",
    "            y_std.append(y_std_i)\n",
    "            \n",
    "        if return_std:\n",
    "            return (y_, y_std)\n",
    "        else:\n",
    "            return (y_,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de la clase\n",
    "\n",
    "Se creará un data set de prueba para experimentar si la clase `RegresionBayesianaEmpirica` funciona. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos que quizas sean necesarios\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal\n",
    "import seaborn as sns # pretty plots\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, d = 5000, 3\n",
    "alpha_real, beta_real = 1, 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v_cero = [0 for i in range(d)]\n",
    "# M_bet_I = (1 / beta_real) * np.eye(d)\n",
    "# w = np.random.multivariate_normal(v_cero, M_bet_I)\n",
    "w = np.array([3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz X y vector y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1] + [np.random.uniform(-5, 5) for _ in range(d-1)] for _ in range(N)\n",
    "])\n",
    "\n",
    "y = np.array([\n",
    "    float(np.inner(w, X[i]) + np.random.normal(0, alpha_real)) for i in range(N)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba de la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_falso, beta_falso = 50000, 2.5\n",
    "\n",
    "rbe = RegresionBayesianaEmpirica(alpha_falso, beta_falso)\n",
    "rbe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.array([\n",
    "    [8, 2, 5],\n",
    "    [2, 4, 9]\n",
    "])\n",
    "rbe.predict(X_, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inner(X_[0], w), np.inner(X_[1], w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbe.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam, _ = np.linalg.eig(beta_falso * X.T@X)\n",
    "beta_falso * X.T@X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
