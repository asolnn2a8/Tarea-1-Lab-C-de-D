{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 1, parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importa el módulo `pandas`, y se importa un módulo personal llamado `paths`, que contiene los paths que utilizaremos en este análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es la documentación de `paths` (decomentar para verlas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentación del módulo 'paths'.\n",
    "# import paths\n",
    "# help(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de la tabla mezclada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar todos los .csv en dos listas distinguidas por la aparición de `furnished` en el nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lista de DataFrames (Sin 'furnished' en el nombre)\n",
    "L_DF_a = [pd.read_csv(dict_csv_mc_a[wNN]) for wNN in L_WNN]\n",
    "\n",
    "# Lista de DataFrames (Con 'furnished' en el nombre)\n",
    "L_DF_f = [pd.read_csv(dict_csv_mc_f[wNN]) for wNN in L_WNN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se unen los `DataFrames` de las listas en un único `DataFrame`, luego se crea una nueva columna llamada `'furnished'` y finalmente se unen los dos `DataFrames` en uno, con la nueva columna incluida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se unen todos los data_frame en cada lista con el comando concat\n",
    "DF_a = pd.concat(L_DF_a)\n",
    "DF_f = pd.concat(L_DF_f)\n",
    "\n",
    "# Se eliminan las filas duplicadas de cada data frame por separado\n",
    "DF_a.drop_duplicates(subset=DF_a.columns, ignore_index=True, inplace=True, keep='last')\n",
    "DF_f.drop_duplicates(subset=DF_f.columns, ignore_index=True, inplace=True, keep='last')\n",
    "\n",
    "# Se crea una columna con tantos ceros como la cantidad de filas de DF_a\n",
    "# y con tantos unos como la cantidad de filas de DF_f \n",
    "furnished_col = pd.DataFrame(data={'furnished':[0]*(DF_a.shape[0]) + [1]*(DF_f.shape[0])})\n",
    "\n",
    "# Concateno los data frames DF_a y DF_f y le agrego al final la columna furnished_col\n",
    "df = pd.concat([DF_a, DF_f], ignore_index=True) \n",
    "df = pd.concat([df, furnished_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemos cuantas filas tiene cada data frame (para reportar si hay filas en furnished \n",
    "# que no estan en all)\n",
    "# print(DF_a.shape[0])\n",
    "# print(DF_f.shape[0])\n",
    "# nota: DF_a tiene 16295 filas y DF_f tiene 2099 filas  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para terminar, se quitan las filas duplicadas en ambos grupos, furnished y all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos las filas que sean iguales en todas las columnas con excepcion de\n",
    "# la columna furnished y reindexamos\n",
    "df.drop_duplicates(subset=df.columns[:-1], ignore_index=True, inplace=True, keep='last')\n",
    "\n",
    "# comentario 1: si hay filas duplicadas con distintos valores de furnished, se eliminan las primera\n",
    "# comentario 2: el comentario 1 asegura que si hay dos filas iguales con distintos valores de furnished,\n",
    "# se elimine la que tiene el valor 0 para furnished, lo que tiene sentido dado que furnished puede estar\n",
    "# contenido en all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reportar si Reporte si existen observaciones de archivos con texto ’furnished’ que no estén\n",
    "# contenidos en archivos con texto ’all’\n",
    "# print(df[df['furnished'] == 0].shape[0])\n",
    "# print(df[df['furnished'] == 1].shape[0])\n",
    "# como ambas selecciones de filas en el dataframe tienen las mismas filas que los originales\n",
    "# luego de eliminar las filas iguales, se conluye que no hay filas en furnished que no esten\n",
    "# en all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1, parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un diccionario llamado `valores_nulos` que contendrá el nombre de las columnas de `df` como llave, y el valor de la llave será lo que reemplazará el valor `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos valores a reemplazar\n",
    "valores_nulos = {\n",
    "#     'property_type|rent_type|location':'Sin nombre',\n",
    "    'price':'$0',\n",
    "    'n_rooms':'NA',\n",
    "    'n_bath':'NA',\n",
    "    'surface':'0.0 m2',\n",
    "#     'details':'',\n",
    "#     'url':'',\n",
    "#     'metrocuadrado_index':0.0,\n",
    "#     'furnished':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos los valores\n",
    "df.fillna(value=valores_nulos, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reemplazo de los tipos de algunas columnas\n",
    "\n",
    "Además, en esta etapa se cambiará el tipo de algunas columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que mapeará la columna `price`\n",
    "def precio_to_int(s:str)->int:\n",
    "    \"\"\"\n",
    "    Toma un precio en forma de `str`, en el formato `'$XXX.XXX.XXX'` \n",
    "    con X algún número, y retorna el número entero de ese precio.\n",
    "    \"\"\"\n",
    "    return int(s.replace('$', '').replace('.', ''))\n",
    "\n",
    "# Función que mapeará la columna `surface`\n",
    "def n_surface(s:str)->float:\n",
    "    \"\"\"\n",
    "    Toma un `str` en formato \"XX.Xm2\" y retorna el número real con los metros cuadrados.\n",
    "    \"\"\"\n",
    "    return float(s.replace('m2', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reemplazo de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columna de precios\n",
    "precios_col = df['price'].map(precio_to_int)\n",
    "# Columna de superficie\n",
    "superficie_col = df['surface'].map(n_surface)\n",
    "\n",
    "df['price'] = precios_col\n",
    "df['surface'] = superficie_col\n",
    "df.rename(columns={\n",
    "    'price':'price_$',\n",
    "    'surface':'surface_m2'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Obtención de 3 columnas a partir de `'property_type|rent_type|location'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lower_case_col` es una columna con todas las palabras en minusculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_case_col = df['property_type|rent_type|location'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columna `tipo de inmueble`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `casa_bool_col` y `apart_bool_col` son columnas que tienen un -1 si la palabra no está \n",
    "# y un número entero positivo si la palabra está.\n",
    "casa_bool_col = lower_case_col.str.find('casa')\n",
    "apart_bool_col = lower_case_col.str.find('apartamento')\n",
    "\n",
    "# Se crea una lista con la infomacion del tipo de inmueble recorriendo las dos columnas anteriores\n",
    "tipo_inm_list = []\n",
    "for index in range(len(lower_case_col)):\n",
    "    if casa_bool_col[index] >= 0:\n",
    "        tipo_inm_list.append('Casa')\n",
    "    elif apart_bool_col[index] >= 0:\n",
    "        tipo_inm_list.append('Apartamento')\n",
    "    else:\n",
    "        tipo_inm_list.append('No hay info')\n",
    "\n",
    "# columna de tipo de inmueble\n",
    "tipo_inm_col = pd.DataFrame(data = {'tipo_de_inmueble': tipo_inm_list})\n",
    "\n",
    "# Nota: no hay columnas que no tengan una de las dos informaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columna `Tipo de oferta`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `vent_bool_col` y `arr_bool_col` son columnas que tienen un -1 si la palabra no está \n",
    "# y un número entero positivo si la palabra está.\n",
    "vent_bool_col = lower_case_col.str.find('venta')\n",
    "arr_bool_col = lower_case_col.str.find('arriendo')\n",
    "\n",
    "# Se crea una lista con la infomacion del tipo de oferta recorriendo las dos columnas anteriores\n",
    "tipo_ofer_list = []\n",
    "for index in range(len(lower_case_col)):\n",
    "    if (vent_bool_col[index] >= 0) and (arr_bool_col[index] >= 0):\n",
    "        tipo_ofer_list.append('Arriendo y venta')\n",
    "    elif arr_bool_col[index] >= 0:\n",
    "        tipo_ofer_list.append('Arriendo')\n",
    "    else:\n",
    "        tipo_ofer_list.append('No hay info')\n",
    "\n",
    "# columna de tipo de oferta\n",
    "tipo_ofer_col = pd.DataFrame(data = {'tipo_de_oferta': tipo_ofer_list})\n",
    "\n",
    "# Nota: no hay columnas que no tengan una de las dos informaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columna `location`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `sep_comas` es una serie que contiene en cada elemento una lista del string correspondiente \n",
    "# que separa por comas los grupos de strings\n",
    "sep_comas = df['property_type|rent_type|location'].str.split(pat = \",\")\n",
    "\n",
    "# Se crea una lista con la infomacion location recorriendo los segundos elementos de la columna anterior\n",
    "# se asume que la direccion esta al final de cada string\n",
    "location_list = []\n",
    "for index in range(len(sep_comas)):\n",
    "    lista_strings = sep_comas[index]\n",
    "    location_list.append(lista_strings[1]) \n",
    "    \n",
    "# columna location\n",
    "location_col = pd.DataFrame(data = {'location': location_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agregar las 3 columnas anteriores a `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,tipo_inm_col], axis=1)\n",
    "df = pd.concat([df,tipo_ofer_col], axis=1)\n",
    "df = pd.concat([df,location_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba de que location_col no tiene el string de arriendo (solo tiene direcciones)\n",
    "# prueba_0 = location_col['location'].str.lower()\n",
    "# prueba_1 = prueba_0.str.find('arriendo')\n",
    "# for index in range(len(prueba_1)):\n",
    "#     if prueba_1[index] >= 0:\n",
    "#         print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1, parte 3\n",
    "\n",
    "### Esquema para agregar las columnas `price per m2` y `garajes`\n",
    "\n",
    "* Se desarrollarán funciones que procesen las columnas `url`.\n",
    "* Se crearán nuevas columnas a partir de las columnas mapeadas a partir de las funciones creadas.\n",
    "* Se agregarán estas columnas a `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones\n",
    "\n",
    "Se detallan las funciones que mapearán las columnas a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que mapeará la columna `url`\n",
    "def n_garaje(s:str)->str: \n",
    "    \"\"\"\n",
    "    Función que toma una url en forma de `str` y retorna un `str`, que será\n",
    "    el número de garajes para la vivienda de esa url.\n",
    "    \"\"\"\n",
    "    i_garaje = s.find('-garajes')\n",
    "    \n",
    "    # No se encuentra el garaje\n",
    "    if i_garaje is -1: \n",
    "        return '0'\n",
    "    \n",
    "    # rescata el str con el número. Puede ser un número de la forma '4+'\n",
    "    s_hasta_garaje = s[:i_garaje] # Se recortará el str hasta la aparición de '-garajes'\n",
    "    i_garaje_ = s_hasta_garaje.rfind('-') + 1 # Se encontrará el índice siguiente de un guión '-'\n",
    "    \n",
    "    return s_hasta_garaje[i_garaje_:] # Se entrega el resto después de ese índice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procesamiento de columnas\n",
    "\n",
    "Se crearán las columnas y se procesarán para ser entregadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columna de los garajes\n",
    "garajes_col = df['url'].map(n_garaje)\n",
    "\n",
    "# Columna producto de la división entre las columnas de precio y superficie\n",
    "p_por_s_col = (df['price_$'] / df['surface_m2']).map(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rotulación de columnas y añadirlas a `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ppm_and_g = pd.DataFrame(\n",
    "    data={\n",
    "        'price_per_m2_$/m2':p_por_s_col,\n",
    "        'garajes':garajes_col\n",
    "    }\n",
    ")\n",
    "\n",
    "df = pd.concat([df, df_ppm_and_g], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1, parte 4\n",
    "\n",
    "### Esquema para clasificar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear las 8 clasificaciones con el comando query, ademas, se crean columnmas con enteros \n",
    "# que representan dicha clasificacion\n",
    "\n",
    "expr_base = 'tipo_de_inmueble == \"{tipo_inmueble}\" ' \\\n",
    "          + 'and surface_m2 >= {cota_inf} ' \\\n",
    "          + 'and surface_m2 {desig} {cota_sup}'\n",
    "\n",
    "L_inmuebles = ['Casa']*5 + ['Apartamento']*3\n",
    "bnds_sym_r = ['<']*4 + ['<='] \\\n",
    "           + ['<']*2 + ['<=']\n",
    "\n",
    "L_bnds_casa = list(map(str, [80, 120, 180, 240, 360, 460]))\n",
    "L_bnds_apart = list(map(str, [40, 60, 80, 120]))\n",
    "\n",
    "bnds = [(L_bnds_casa[i], L_bnds_casa[i+1]) for i in range(len(L_bnds_casa)-1)] \\\n",
    "     + [(L_bnds_apart[i], L_bnds_apart[i+1]) for i in range(len(L_bnds_apart)-1)]\n",
    "\n",
    "L_expr = [expr_base.format(\n",
    "    tipo_inmueble=L_inmuebles[i], \n",
    "    cota_inf=bnds[i][0], \n",
    "    desig=bnds_sym_r[i], \n",
    "    cota_sup=bnds[i][1]\n",
    ") for i in range(len(bnds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_prod = []\n",
    "tipo_prod_list = []\n",
    "\n",
    "for i in range(len(L_expr)):\n",
    "    prod = df.query(L_expr[i], inplace=False)\n",
    "    list_prod = [i+1]*(prod.shape[0])\n",
    "    \n",
    "    L_prod.append(prod)\n",
    "    tipo_prod_list += list_prod\n",
    "\n",
    "# concateno todos los productos reseteando los indices\n",
    "df = pd.concat(L_prod, ignore_index=True) \n",
    "# creo la columna con el tipo de producto\n",
    "tipo_prod = pd.DataFrame(data={'Tipo_de_prod': tipo_prod_list})\n",
    "# agrego la columna de tipo de producto\n",
    "df = pd.concat([df, tipo_prod], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1, parte 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar data\n",
    "df_upz = pd.read_csv(path_csv_barrio_upz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea la columna location que es la columna 'location' de df, a la que \n",
    "# se le cambian todas las letras por minusculas y se le hace un split \n",
    "# para ver las palabras enlistadas   \n",
    "location = df['location'].str.lower()\n",
    "location = location.str.split(pat=\" \")\n",
    "\n",
    "# se crea la columna pro_location que es la columna 'pro_location' de df_upz, a la que \n",
    "# se le cambian todas las letras por minusculas y se le hace un split \n",
    "# para ver las palabras enlistadas   \n",
    "pro_location = df_upz['pro_location'].str.lower()\n",
    "pro_location = pro_location.str.split(pat=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se crea una lista con los codigos de upz de df_upz que corresponden a cada fila de df\n",
    "# en caso de que no se encuentre ningun representante en df_upz, se pone un -1\n",
    "# Se usa el hecho de que uan fila en df se puede asignar a lo mas a una fila en upz \n",
    "# (algoritmo celda siguiente)\n",
    "upz_list = []\n",
    "\n",
    "# Se elige un elemento (lista por el split) de location\n",
    "for name_df_completo in location:\n",
    "    # Se acorta para sacar el primer elemento (['']) y el los dos ultimos (['Bogota', 'D.C..'])\n",
    "    name_df = name_df_completo[1:-2] \n",
    "    # se fija un indice inicial para iterar sobre todos los indices de df_upz hasta encontrar\n",
    "    # un representante\n",
    "    indice_upz = 0  \n",
    "    index_encontrado = False \n",
    "    while not(index_encontrado) and indice_upz < len(pro_location):\n",
    "        # nos aseguramos que es una lista desde el split y no un 'nan'\n",
    "        if type(pro_location[indice_upz]) is list:\n",
    "            # vemos si pro_location[indice_upz] es el representante \n",
    "            if pro_location[indice_upz] == name_df:\n",
    "                # en este caso paramos el loop\n",
    "                index_encontrado = True \n",
    "            # sino, se continua con el otro indice \n",
    "            else:\n",
    "                indice_upz = indice_upz + 1\n",
    "        # sino, se continua con el otro indice \n",
    "        else:\n",
    "            indice_upz = indice_upz + 1 \n",
    "    # Luego terminar el loop, tenemos dos casos\n",
    "    # se encontro un indice\n",
    "    if index_encontrado:\n",
    "        upz_list.append(df_upz['UPlCodigo'][indice_upz]) \n",
    "    else:\n",
    "        upz_list.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear columna de codigo upz y agregar al dataframe df\n",
    "upz_code = pd.DataFrame(data={'upz_codigo': upz_list})\n",
    "df = pd.concat([df, upz_code], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero de observaciones que no tienen codigo upz asignado\n",
    "print('Numero de observaciones sin codigo upz asignado:', df[df['upz_codigo'] == -1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barrios que no tienen codigo upz asigando (sin repeticion por el set)\n",
    "barrios = set((df[df['upz_codigo'] == -1]['location']).tolist())\n",
    "# Numero de barrios sin codigo upz\n",
    "print('Numero de barrios sin codigo upz:', len(barrios))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1, parte 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
