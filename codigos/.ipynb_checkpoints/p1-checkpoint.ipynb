{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 1, parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importa el módulo `pandas`, y se importa un módulo personal llamado `paths`, que contiene los paths que utilizaremos en este análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es la documentación de `paths` (decomentar para verlas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentación del módulo 'paths'.\n",
    "# import paths\n",
    "# help(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de la tabla mezclada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar todos los .csv en dos listas distinguidas por la aparición de `furnished` en el nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lista de DataFrames (Sin 'furnished' en el nombre)\n",
    "L_DF_a = [pd.read_csv(dict_csv_mc_a[wNN]) for wNN in L_WNN]\n",
    "\n",
    "# Lista de DataFrames (Con 'furnished' en el nombre)\n",
    "L_DF_f = [pd.read_csv(dict_csv_mc_f[wNN]) for wNN in L_WNN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se unen los `DataFrames` de las listas en un único `DataFrame`, luego se crea una nueva columna llamada `'furnished'` y finalmente se unen los dos `DataFrames` en uno, con la nueva columna incluida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se unen todos los data_frame en cada lista con el comando concat\n",
    "DF_a = pd.concat(L_DF_a)\n",
    "DF_f = pd.concat(L_DF_f)\n",
    "\n",
    "# Se eliminan las filas duplicadas de cada data frame por separado\n",
    "DF_a.drop_duplicates(subset=DF_a.columns, ignore_index=True, inplace=True, keep='last')\n",
    "DF_f.drop_duplicates(subset=DF_f.columns, ignore_index=True, inplace=True, keep='last')\n",
    "\n",
    "# Se crea una columna con tantos ceros como la cantidad de filas de DF_a\n",
    "# y con tantos unos como la cantidad de filas de DF_f \n",
    "furnished_col = pd.DataFrame(data={'furnished':[0]*(DF_a.shape[0]) + [1]*(DF_f.shape[0])})\n",
    "\n",
    "# Concateno los data frames DF_a y DF_f y le agrego al final la columna furnished_col\n",
    "df = pd.concat([DF_a, DF_f], ignore_index=True) \n",
    "df = pd.concat([df, furnished_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemos cuantas filas tiene cada data frame (para reportar si hay filas en furnished \n",
    "# que no estan en all)\n",
    "# print(DF_a.shape[0])\n",
    "# print(DF_f.shape[0])\n",
    "# nota: DF_a tiene 16295 filas y DF_f tiene 2099 filas  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para terminar, se quitan las filas duplicadas en ambos grupos, furnished y all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos las filas que sean iguales en todas las columnas con excepcion de\n",
    "# la columna furnished y reindexamos\n",
    "df.drop_duplicates(subset=df.columns[:-1], ignore_index=True, inplace=True, keep='last')\n",
    "\n",
    "# comentario 1: si hay filas duplicadas con distintos valores de furnished, se eliminan las primera\n",
    "# comentario 2: el comentario 1 asegura que si hay dos filas iguales con distintos valores de furnished,\n",
    "# se elimine la que tiene el valor 0 para furnished, lo que tiene sentido dado que furnished puede estar\n",
    "# contenido en all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reportar si Reporte si existen observaciones de archivos con texto ’furnished’ que no estén\n",
    "# contenidos en archivos con texto ’all’\n",
    "# print(df[df['furnished'] == 0].shape[0])\n",
    "# print(df[df['furnished'] == 1].shape[0])\n",
    "# como ambas selecciones de filas en el dataframe tienen las mismas filas que los originales\n",
    "# luego de eliminar las filas iguales, se conluye que no hay filas en furnished que no esten\n",
    "# en all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1, parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un diccionario llamado `valores_nulos` que contendrá el nombre de las columnas de `df` como llave, y el valor de la llave será lo que reemplazará el valor `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos valores a reemplazar\n",
    "valores_nulos = {\n",
    "#     'property_type|rent_type|location':'Sin nombre',\n",
    "    'price':'$0',\n",
    "    'n_rooms':'NA',\n",
    "    'n_bath':'NA',\n",
    "    'surface':'0.0 m2',\n",
    "#     'details':'',\n",
    "#     'url':'',\n",
    "#     'metrocuadrado_index':0.0,\n",
    "#     'furnished':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos los valores\n",
    "df.fillna(value=valores_nulos, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reemplazo de los tipos de algunas columnas\n",
    "\n",
    "Además, en esta etapa se cambiará el tipo de algunas columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que mapeará la columna `price`\n",
    "def precio_to_int(s:str)->int:\n",
    "    \"\"\"\n",
    "    Toma un precio en forma de `str`, en el formato `'$XXX.XXX.XXX'` \n",
    "    con X algún número, y retorna el número entero de ese precio.\n",
    "    \"\"\"\n",
    "    return int(s.replace('$', '').replace('.', ''))\n",
    "\n",
    "# Función que mapeará la columna `surface`\n",
    "def n_surface(s:str)->float:\n",
    "    \"\"\"\n",
    "    Toma un `str` en formato \"XX.Xm2\" y retorna el número real con los metros cuadrados.\n",
    "    \"\"\"\n",
    "    return float(s.replace('m2', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reemplazo de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columna de precios\n",
    "precios_col = df['price'].map(precio_to_int)\n",
    "# Columna de superficie\n",
    "superficie_col = df['surface'].map(n_surface)\n",
    "\n",
    "df['price'] = precios_col\n",
    "df['surface'] = superficie_col\n",
    "df.rename(columns={\n",
    "    'price':'price [$]',\n",
    "    'surface':'surface [m2]'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Obtención de 3 columnas a partir de `'property_type|rent_type|location'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lower_case_col` es una columna con todas las palabras en minusculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_case_col = df['property_type|rent_type|location'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columna `tipo de inmueble`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `casa_bool_col` y `apart_bool_col` son columnas que tienen un -1 si la palabra no está \n",
    "# y un número entero positivo si la palabra está.\n",
    "casa_bool_col = lower_case_col.str.find('casa')\n",
    "apart_bool_col = lower_case_col.str.find('apartamento')\n",
    "\n",
    "# Se crea una lista con la infomacion del tipo de inmueble recorriendo las dos columnas anteriores\n",
    "tipo_inm_list = []\n",
    "for index in range(len(lower_case_col)):\n",
    "    if casa_bool_col[index] >= 0:\n",
    "        tipo_inm_list.append('Casa')\n",
    "    elif apart_bool_col[index] >= 0:\n",
    "        tipo_inm_list.append('Apartamento')\n",
    "    else:\n",
    "        tipo_inm_list.append('No hay info')\n",
    "\n",
    "# columna de tipo de inmueble\n",
    "tipo_inm_col = pd.DataFrame(data = {'Tipo_de_inmueble': tipo_inm_list})\n",
    "\n",
    "# Nota: no hay columnas que no tengan una de las dos informaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columna `Tipo de oferta`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `vent_bool_col` y `arr_bool_col` son columnas que tienen un -1 si la palabra no está \n",
    "# y un número entero positivo si la palabra está.\n",
    "vent_bool_col = lower_case_col.str.find('venta')\n",
    "arr_bool_col = lower_case_col.str.find('arriendo')\n",
    "\n",
    "# Se crea una lista con la infomacion del tipo de oferta recorriendo las dos columnas anteriores\n",
    "tipo_ofer_list = []\n",
    "for index in range(len(lower_case_col)):\n",
    "    if (vent_bool_col[index] >= 0) and (arr_bool_col[index] >= 0):\n",
    "        tipo_ofer_list.append('Arriendo y venta')\n",
    "    elif arr_bool_col[index] >= 0:\n",
    "        tipo_ofer_list.append('Arriendo')\n",
    "    else:\n",
    "        tipo_ofer_list.append('No hay info')\n",
    "\n",
    "# columna de tipo de oferta\n",
    "tipo_ofer_col = pd.DataFrame(data = {'Tipo_de_oferta': tipo_ofer_list})\n",
    "\n",
    "# Nota: no hay columnas que no tengan una de las dos informaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columna `location`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `sep_comas` es una serie que contiene en cada elemento una lista del string correspondiente \n",
    "# que separa por comas los grupos de strings\n",
    "sep_comas = df['property_type|rent_type|location'].str.split(pat = \",\")\n",
    "\n",
    "# Se crea una lista con la infomacion location recorriendo los segundos elementos de la columna anterior\n",
    "# se asume que la direccion esta al final de cada string\n",
    "location_list = []\n",
    "for index in range(len(sep_comas)):\n",
    "    lista_strings = sep_comas[index]\n",
    "    location_list.append(lista_strings[1]) \n",
    "    \n",
    "# columna location\n",
    "location_col = pd.DataFrame(data = {'location': location_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agregar las 3 columnas anteriores a `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,tipo_inm_col], axis=1)\n",
    "df = pd.concat([df,tipo_ofer_col], axis=1)\n",
    "df = pd.concat([df,location_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba de que location_col no tiene el string de arriendo (solo tiene direcciones)\n",
    "# prueba_0 = location_col['location'].str.lower()\n",
    "# prueba_1 = prueba_0.str.find('arriendo')\n",
    "# for index in range(len(prueba_1)):\n",
    "#     if prueba_1[index] >= 0:\n",
    "#         print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1, parte 3\n",
    "\n",
    "### Esquema para agregar las columnas `price per m2` y `garajes`\n",
    "\n",
    "* Se desarrollarán funciones que procesen las columnas `url`.\n",
    "* Se crearán nuevas columnas a partir de las columnas mapeadas a partir de las funciones creadas.\n",
    "* Se agregarán estas columnas a `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones\n",
    "\n",
    "Se detallan las funciones que mapearán las columnas a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que mapeará la columna `url`\n",
    "def n_garaje(s:str)->str: \n",
    "    \"\"\"\n",
    "    Función que toma una url en forma de `str` y retorna un `str`, que será\n",
    "    el número de garajes para la vivienda de esa url.\n",
    "    \"\"\"\n",
    "    i_garaje = s.find('-garajes')\n",
    "    \n",
    "    # No se encuentra el garaje\n",
    "    if i_garaje is -1: \n",
    "        return '0'\n",
    "    \n",
    "    # rescata el str con el número. Puede ser un número de la forma '4+'\n",
    "    s_hasta_garaje = s[:i_garaje] # Se recortará el str hasta la aparición de '-garajes'\n",
    "    i_garaje_ = s_hasta_garaje.rfind('-') + 1 # Se encontrará el índice siguiente de un guión '-'\n",
    "    \n",
    "    return s_hasta_garaje[i_garaje_:] # Se entrega el resto después de ese índice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procesamiento de columnas\n",
    "\n",
    "Se crearán las columnas y se procesarán para ser entregadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columna de los garajes\n",
    "garajes_col = df['url'].map(n_garaje)\n",
    "\n",
    "# Columna producto de la división entre las columnas de precio y superficie\n",
    "p_por_s_col = df['price [$]'] / df['surface [m2]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rotulación de columnas y añadirlas a `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ppm_and_g = pd.DataFrame(\n",
    "    data={\n",
    "        'price per m2 [$/m2]':p_por_s_col,\n",
    "        'garajes':garajes_col\n",
    "    }\n",
    ")\n",
    "\n",
    "df = pd.concat([df, df_ppm_and_g], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1, parte 4\n",
    "\n",
    "### Esquema para clasificar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear las 8 clasificaciones con el comando query, ademas, se crean columnmas con enteros \n",
    "# que representan dicha clasificacion\n",
    "\n",
    "# Tipo de producto 1\n",
    "prod_1 = df.query('Tipo_de_inmueble == \"Casa\" and surface >= 80 and surface < 120', inplace = False)\n",
    "list_prod_1 = [1]*(prod_1.shape[0])\n",
    "# Tipo de producto 2\n",
    "prod_2 = df.query('Tipo_de_inmueble == \"Casa\" and surface >= 120 and surface < 180', inplace = False)\n",
    "list_prod_2 = [2]*(prod_2.shape[0])\n",
    "# Tipo de producto 3\n",
    "prod_3 = df.query('Tipo_de_inmueble == \"Casa\" and surface >= 180 and surface < 240', inplace = False)\n",
    "list_prod_3 = [3]*(prod_3.shape[0])\n",
    "# Tipo de producto 4\n",
    "prod_4 = df.query('Tipo_de_inmueble == \"Casa\" and surface >= 240 and surface < 360', inplace = False)\n",
    "list_prod_4 = [4]*(prod_4.shape[0])\n",
    "# Tipo de producto 5\n",
    "prod_5 = df.query('Tipo_de_inmueble == \"Casa\" and surface >= 360 and surface <= 460', inplace = False)\n",
    "list_prod_5 = [5]*(prod_5.shape[0])\n",
    "# Tipo de producto 6\n",
    "prod_6 = df.query('Tipo_de_inmueble == \"Apartamento\" and surface >= 40 and surface < 60', inplace = False)\n",
    "list_prod_6 = [6]*(prod_6.shape[0])\n",
    "# Tipo de producto 7\n",
    "prod_7 = df.query('Tipo_de_inmueble == \"Apartamento\" and surface >= 60 and surface < 80', inplace = False)\n",
    "list_prod_7 = [7]*(prod_7.shape[0])\n",
    "# Tipo de producto 8\n",
    "prod_8 = df.query('Tipo_de_inmueble == \"Apartamento\" and surface >= 80 and surface <= 120', inplace = False)\n",
    "list_prod_8 = [8]*(prod_8.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
