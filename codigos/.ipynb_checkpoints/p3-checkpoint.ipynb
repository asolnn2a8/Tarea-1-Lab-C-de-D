{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 3: Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1\n",
    "Se implementará la clase `RegresionBayesianaEmpirica`, que heredará las clases [`BaseEstimator`](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html) y [`RegressorMixin`](http://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html), que son clases del paquete [`sklearn.base`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de la clase `RegresionBayesianaEmpirica`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegresionBayesianaEmpirica(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    `RegresionBayesianaEmpirica` es una clase que hereda de `sklearn.base.BaseEstimator` y \n",
    "    `sklearn.base.RegressorMixin` el cual implementa la heurística enunciada en el \n",
    "    informe de la tarea para aproximar los hiperparámetros óptimos de alpha y beta.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha_0, beta_0, tol=1e-5, maxiter=200):\n",
    "        self.alpha = alpha_0\n",
    "        self.beta = beta_0\n",
    "        self.__tol = tol\n",
    "        self.__maxiter = maxiter\n",
    "        \n",
    "    def get_posterior(self, X, y, alpha, beta):\n",
    "        \"\"\"\n",
    "        Recibe una matriz de observaciones 'X' (de dimensiones N x d), el vector de \n",
    "        etiquetas 'y' (de dimensión N) y los hiperparámetros 'alpha' y 'beta'.\n",
    "        \n",
    "        Retorna una tupla (m_N, S_N), dónde 'm_N' corresponde al vector de medias y \n",
    "        'S_N' corresponde a la matriz de covarianzas de la posterior de 'w'.\n",
    "        \"\"\"\n",
    "        # Se ocupa P3-1\n",
    "        # dimensiones\n",
    "        N, d = X.shape\n",
    "        \n",
    "        # Matriz de covarianzas [d x d]\n",
    "        S_N_inv = alpha*np.eye(d) + beta*X.T@X\n",
    "        S_N = S_N_inv.I\n",
    "        \n",
    "        # Vector de medias [d]\n",
    "        m_N = beta * (S_N@X.T@y)\n",
    "        \n",
    "        return (m_N, S_N)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Recibe una matriz de observaciones 'X' (de dimensiones N x d) \n",
    "        y un vector de etiquetas 'y' (de dimensión N).\n",
    "        \n",
    "        Ajusta los valores de 'alpha' y 'beta'.\n",
    "        \"\"\"\n",
    "        # Seteamos atributos de los datos y dimensiones\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.N, self.d = self.X.shape\n",
    "        \n",
    "        maxiter_alcanzado = True # Variable para saber si la \n",
    "                                  # máxima iteración ha sido cumplida o no\n",
    "        \n",
    "        for _ in range(self.__maxiter):\n",
    "            # Seteamos alpha_0 y beta_0 \n",
    "            alpha_0, beta_0 = self.alpha, self.beta\n",
    "            \n",
    "            # Calculamos los valores propios de beta * X^t * X\n",
    "            lamb, _ = np.linalg.eig(beta * self.X.T@self.X)\n",
    "            \n",
    "            # Calculamos gamma\n",
    "            gamma = sum([lamb[i] / (alpha_0 + lamb[i]) for i in range(self.d)])\n",
    "            \n",
    "            # Calculamos m_N\n",
    "            m_N, S_N = self.get_posterior(self.X, self.y, alpha_0, beta_0)\n",
    "            \n",
    "            # Calculamos el siguiente valor de alpha\n",
    "            alpha_1 = gamma / (m_N.T@m_N)\n",
    "            \n",
    "            # Y calculamos el siguiente valor de beta\n",
    "            beta_1_inv = (1 / (self.N-gamma)) \\\n",
    "                     * sum([(self.i[i] - m_N.T@self.X.T[i])**2 for i in range(self.N)])\n",
    "            beta_1 = 1 / beta_1_inv\n",
    "            \n",
    "            # Seteamos estos nuevos valores para alpha y beta\n",
    "            self.alpha, self.beta = alpha_1, beta_1\n",
    "            \n",
    "            # Comparamos para saber si ya se cumplió la condición de cercanía\n",
    "            if (abs(alpha_0 - alpha_1) <= self.__tol\n",
    "               and abs(beta_0 - beta_1) <= self.__tol):\n",
    "                print('tolerancia alcanzada')\n",
    "                maxiter_alcanzado = False\n",
    "                break\n",
    "        \n",
    "        if maxiter_alcanzado:\n",
    "            print('alcanzado numero max de iter')\n",
    "        \n",
    "        return self\n",
    "            \n",
    "    \n",
    "    def predict(self, X_, return_std=False)->tuple:\n",
    "        \"\"\"\n",
    "        Recibe una matriz de observaciones 'X_' (de dimensiones N' x d).\n",
    "        \n",
    "        Retorna una tupla (y_, y_std), en dónde 'y_' corresponde al vector de medias y 'y_std' \n",
    "        corresponde al vector de desviaciones estándar asociadas a las observaciones de 'X_'.\n",
    "        Haciendo notar que esto ocurre solo sí 'return_std' es True. En caso contrario, solo retorna \n",
    "        la tupla (y_,).\n",
    "        \n",
    "        Se ocupa la distribución predictiva posterior para estas predicciones.\n",
    "        \"\"\"\n",
    "        # Se ocupa P3-2\n",
    "        # Dimensiones necesarias\n",
    "        N_, d = X_.shape\n",
    "        m_N, S_N = self.get_posterior(self.X, self.y, self.alpha, self.beta)\n",
    "        \n",
    "        y_ = []\n",
    "        y_std = []\n",
    "        for i_ in range(N_):\n",
    "            x_i = X_.T[i_]\n",
    "            y_i = m_N.T@x_i\n",
    "            y_std_i = 1/self.beta + x_i.T@S_N@x_i\n",
    "            \n",
    "            y_.append(y_i)\n",
    "            y_std.append(y_std_i)\n",
    "            \n",
    "        if return_std:\n",
    "            return (y_, y_std)\n",
    "        else:\n",
    "            return (y_,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 4, 5\n",
    "X = np.matrix([[1, 2, 3], [4, 5, 6]])\n",
    "S = a*np.eye(3) + b*X.T@X\n",
    "S.I@S\n",
    "N, d = X.shape\n",
    "print(N, d)\n",
    "c = (5,)\n",
    "\n",
    "class Prueba:\n",
    "    def __init__(self, t):\n",
    "        self.x, self.y = t\n",
    "     \n",
    "tup = (4, 5)\n",
    "p = Prueba(tup)\n",
    "p.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
